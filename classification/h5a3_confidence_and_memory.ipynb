{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO RUN\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\"Machine learning tools\"\n",
    "\n",
    "from classification.datasets import Dataset\n",
    "from classification.utils.audio_student import AudioUtil, Feature_vector_DS\n",
    "\n",
    "#TODO: Adapt if PCA is used or not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Useful functions to select, read and play the dataset sounds are provided in the ``classification`` directory. <br>\n",
    "\n",
    "As for the H1, you will have to fill some short pieces of code, as well as answer some questions. We already created cells for you to answer the questions to ensure you don't forget it ;). <br>\n",
    "You will find the zones to be briefly filled  with a ``### TO COMPLETE`` in the cells below.\n",
    "\n",
    "<font size=6 color=#009999> 3. Probability vector and memory  [~30min-1h] </font> <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO RUN\n",
    "dataset = Dataset()\n",
    "classnames = dataset.list_classes()\n",
    "\n",
    "print(\"\\n\".join(classnames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO RUN\n",
    "fm_dir = \"data/feature_matrices/\"  # where to save the features matrices\n",
    "model_dir = \"data/models/\"  # where to save the models\n",
    "os.makedirs(fm_dir, exist_ok=True)\n",
    "os.makedirs(model_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color=#009999> 3.1. Probability vector </font> <br>\n",
    "\n",
    "A clear drawback of the models considered in ``hands_on_classif2_audio_student.ipynb`` is that they only output the most probable class, but do not provide any confidence estimate of this prediction. It is generally better to output a vector of probabilities for all the classes at each prediction, hence allowing the models to hesitate between different classes. \n",
    "Remember a vector of probability can be defined as \n",
    "\n",
    "\\begin{equation*}\n",
    "    \\mathbb P \\{ i \\} \\in [0,1], ~~\\sum_i \\mathbb P \\{ i \\} = 1. \n",
    "\\end{equation*}\n",
    "\n",
    "There are many ways to do so:\n",
    "\n",
    "- **Adapt the models**, e.g. for the ``KNN`` classifier, give the probability of class ``i`` as the ratio between the number of neighbours with label ``i`` and the total number of considered neighbours ``K``.\n",
    "- **Use other models**: a ``CNN`` classifier is suited for outputting probability values for each class.\n",
    "- **Compare with old predictions**: the probability of class ``i`` may simply be given as the ratio of its appearances in the (arbitrarily chosen) ``N`` last predictions.\n",
    "\n",
    "The last bullet implies the use of old predictions to compute a probability estimate. This leads to the notion of memory in the predictions, that we discuss in the second part of this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us start by creating a dataset ``myds`` and taking the model trained in ````hands_on_classif2_audio.ipynb````.\n",
    "\n",
    "Don't forget to normalize your feature vectors as well as reduce their dimensionality if you trained your model with such data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pickle\n",
    "\n",
    "### TO COMPLETE - Uncomment the following line\n",
    "#model = pickle.load(open('/home/martin/Documents/EPL/M1/Project-Embedded/LELEC210X/classification/data/models/KNN_noPCA.pickle', 'rb'))\n",
    "model = pickle.load(open('data/models/RF_model.pkl', 'rb'))\n",
    "normalize = True\n",
    "\n",
    "pca = None\n",
    "#pca = pickle.load(open('data/models/pca_5FV.pickle', 'rb')) # Write your path to the model here!\n",
    "\n",
    "print(model)\n",
    "print(pca)\n",
    "\n",
    "\"Creation of the dataset\"\n",
    "myds = Feature_vector_DS(\n",
    "    dataset, Nft=512, nmel=20, duration=950, shift_pct=0.0, normalize=normalize, pca=pca,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open-Source code makes life easy! The ``KNeighborsClassifier`` from Sklearn already contains a ``predict_proba`` method. Start getting some intuition on this probability vector by playing with the chosen feature vector. <br>\n",
    "\n",
    "Run the following code many times by changing  ``cls_index``. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO RUN\n",
    "cls_index = [\"fire\", 0]\n",
    "myds.display(cls_index)\n",
    "thisfv = myds.__getitem__(cls_index).reshape(-1)\n",
    "\n",
    "# this artefact is necessary because the 'predict' function expects a matrix_like input.\n",
    "mat = np.zeros((2, len(thisfv)))\n",
    "mat[0] = thisfv\n",
    "\n",
    "#Warning: need to skip PCA otherwise mat have not the right shape\n",
    "prediction_knn = model.predict(mat)\n",
    "print(\"Class predicted by KNN:\", prediction_knn[0])\n",
    "\n",
    "proba_knn = model.predict_proba(mat)\n",
    "plt.figure()\n",
    "plt.bar(classnames, proba_knn[0])\n",
    "plt.title(\"Probability of each class\")\n",
    "#Add the proba value on the plot\n",
    "for i, v in enumerate(proba_knn[0]):\n",
    "    plt.text(i - 0.25, v + 0.01, str(round(v, 2)))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**:\n",
    "When the classifier miss-predicts, how distributed is the probability vector? Is it good news? How can we exploit that probability distribution for the prediction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO COMPLETE\n",
    "# Answer the question above\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer\n",
    "* Miss-prediction for chainsaw: helicopter. The proba for chainsaw is 0.49 and the proba for helicopter is 0.51. It means that both features are near in the features vector space.\n",
    "* Miss-prediction for fire: helicopte. Birds: 0.1, Chainsaw: 0.1, fire: 0.3, handsaw: 0, helicopter: 0.5. It means that the model sees a lot more \"helicopter information\" in fire sound than fire itself.\n",
    "* Miss-prediction for handsaw: chainsaw. birds: 0.29, chainsaw: 0.39, fire: 0, handsaw: 0.31, helicopter: 0. Same the previous but with chainsaw and handsaw. \\\n",
    "\n",
    "These informations are good news, because it shows that the model's wrong predictions have a non negligible probability for the correct or other features. This information can be used to express the uncertainity of the model. For example, with the chainsaw missprediction with helicopter, both probabilies were really close, so we could add a layer to our model that don't accept the prediction because it is too much uncertain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=6 color=#009999> 3.2. Memory </font> <br>\n",
    "\n",
    "No matter if the predictions are one class only or probability vectors, as it is natural that consecutive feature vectors belong to the same class if the sound type changes slowlier than the duration of a feature vector, it can be helpful to link consecutive predictions and see how similar they are to either strengthen or decrease our confidence in the current guess. <br>\n",
    "\n",
    "Here, we will compare the predictions made on consecutive feature vectors belonging to the same 5s-long sound. \n",
    "Run the following code with different ``class_id``'s and different ``num``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO RUN\n",
    "num = 0  # 0 (default), 1, ..., 3\n",
    "#What does num correspond to?\n",
    "# num is the index of the sound in the dataset\n",
    "\n",
    "classname = \"helicopter\"\n",
    "sound = dataset[classname, num]\n",
    "audio = AudioUtil.open(sound)\n",
    "audio = AudioUtil.resample(audio, 11025)\n",
    "#AudioUtil.play(audio)\n",
    "\n",
    "\n",
    "\"Bar charts for each window\"\n",
    "n_win = 5\n",
    "probs = np.zeros((n_win, len(classnames)))\n",
    "for window in range(n_win):\n",
    "    sub_aud = (audio[0][window * 11025 :], audio[1])\n",
    "    sub_aud = AudioUtil.pad_trunc(sub_aud, 950)\n",
    "    sgram = AudioUtil.melspectrogram(sub_aud, Nmel=20)\n",
    "    #plot the spectrogram\n",
    "    #plt.figure()\n",
    "    #plt.imshow(sgram, origin=\"lower\")\n",
    "\n",
    "    ncol = int(1000 * 11025 / (1e3 * 512))\n",
    "    sgram = sgram[:, :ncol]\n",
    "    fv = sgram.reshape(-1)\n",
    "    #fv = myds.__getitem__(cls_index).reshape(-1)\n",
    "    #mat = np.zeros((2, len(fv)))\n",
    "    #mat[0] = fv\n",
    "\n",
    "    #adapt if PCA is used #TODO: TO CORRECT\n",
    "    if pca is not None:\n",
    "        fv = pca.transform([fv])[0]\n",
    "\n",
    "    ### TO COMPLETE - Eventually normalize and reduce feature vector dimensionality\n",
    "    #Normalize the vector\n",
    "    fv = fv / np.linalg.norm(fv)\n",
    "\n",
    "    probs[window, :] = model.predict_proba([fv])[0]\n",
    "    #probs[window, :] = model.predict_proba([fv])\n",
    "\n",
    "    #print(probs[window, :])\n",
    "\n",
    "\"Mean bar chart\"\n",
    "plt.figure()\n",
    "for window in range(n_win):\n",
    "    plt.bar(\n",
    "        np.arange(len(classnames)) * 2 * n_win + window,\n",
    "        probs[window, :] * 100,\n",
    "        alpha=0.9,\n",
    "        label=f\"Window {window}\",\n",
    "    )\n",
    "plt.legend()\n",
    "plt.gca().set_xticks(np.arange(len(classnames)) * 2 * n_win + 2)\n",
    "plt.gca().set_xticklabels(classnames)\n",
    "plt.title(f\"Probability of each window for one {classname} sound\")\n",
    "plt.ylabel(\"Probability (%)\")\n",
    "plt.savefig(f\"figures/proba_windows_{classname}.pdf\")\n",
    "plt.show()\n",
    "\n",
    "\"Mean bar chart\"\n",
    "plt.figure()\n",
    "plt.bar(np.arange(len(classnames)), np.mean(probs, axis=0))\n",
    "plt.gca().set_xticks(np.arange(len(classnames)))\n",
    "plt.gca().set_xticklabels(classnames)\n",
    "#Add the proba value on the plot\n",
    "for i, v in enumerate(np.mean(probs, axis=0)):\n",
    "    plt.text(i - 0.25, v + 0.01, str(round(v, 2)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "classnames = [\"birds\", \"chainsaw\", \"fire\", \"handsaw\", \"helicopter\"]\n",
    "num_range = range(1, 25)  # Assuming 40 audio files to process\n",
    "\n",
    "# Dictionary to store results\n",
    "def get_results_dic_OLD(dataset, n_win, classname):\n",
    "    results_dict = {classname: {\"predictions\": 0} for classname in classnames}\n",
    "    \n",
    "    for num in num_range:\n",
    "        # Load sound for the current num\n",
    "        sound = dataset[classname, num]\n",
    "        audio = AudioUtil.open(sound)\n",
    "        audio = AudioUtil.resample(audio, 11025)\n",
    "\n",
    "        # If n_win is 0, treat the entire audio file as one \"window\" without splitting\n",
    "        # Initialize probabilities for the windows\n",
    "        probs = np.zeros((n_win, len(classnames)))\n",
    "\n",
    "        for window in range(n_win):\n",
    "            # Extract audio for the current window\n",
    "            start_idx = window * 11025\n",
    "            sub_aud = (audio[0][start_idx:], audio[1])\n",
    "            sub_aud = AudioUtil.pad_trunc(sub_aud, 950)\n",
    "            \n",
    "            # Compute mel spectrogram for the window\n",
    "            sgram = AudioUtil.melspectrogram(sub_aud, Nmel=20)\n",
    "            ncol = int(1000 * 11025 / (1e3 * 512))\n",
    "            sgram = sgram[:, :ncol]\n",
    "            fv = sgram.reshape(-1)\n",
    "            \n",
    "            # Apply PCA if needed (ensure it results in 400 features)\n",
    "            if pca is not None:\n",
    "                fv = pca.transform([fv])[0]\n",
    "            \n",
    "            # Normalize the feature vector\n",
    "            fv = fv / np.linalg.norm(fv)\n",
    "            \n",
    "            \n",
    "            # Predict probabilities for the current window\n",
    "            probs[window, :] = model.predict_proba([fv])[0]\n",
    "            #print(probs[window, :])\n",
    "\n",
    "        # Compute mean probabilities over all windows (if needed, but you can skip this if not required)\n",
    "        mean_probs = np.mean(probs, axis=0)\n",
    "        #print(mean_probs)\n",
    "        \n",
    "        # Determine the predicted class for this num and increment the counter\n",
    "        predicted_class_idx = np.argmax(mean_probs)\n",
    "        predicted_class = classnames[predicted_class_idx]\n",
    "        results_dict[predicted_class][\"predictions\"] += 1\n",
    "\n",
    "    return results_dict\n",
    "\n",
    "# Dictionary to store results\n",
    "def get_results_dic(melvecs, n_win, classname):\n",
    "    results_dict = {classname: {\"predictions\": 0} for classname in classnames}\n",
    "    \n",
    "    for num in num_range:\n",
    "        melvec = melvecs[num-1]\n",
    "\n",
    "        # If n_win is 0, treat the entire audio file as one \"window\" without splitting\n",
    "        # Initialize probabilities for the windows\n",
    "        probs = np.zeros((n_win, len(classnames)))\n",
    "\n",
    "        for window in range(n_win):\n",
    "            start_idx = window * 400\n",
    "            fv = melvec.reshape(1, -1)[0][start_idx:]\n",
    "            fv = fv[0:400]\n",
    "            \n",
    "            # Apply PCA if needed (ensure it results in 400 features)\n",
    "            if pca is not None:\n",
    "                fv = pca.transform([fv])[0]\n",
    "            \n",
    "            # Normalize the feature vector\n",
    "            fv = fv / np.linalg.norm(fv)\n",
    "            \n",
    "            \n",
    "            # Predict probabilities for the current window\n",
    "            probs[window, :] = model.predict_proba([fv])[0]\n",
    "\n",
    "        # Compute mean probabilities over all windows (if needed, but you can skip this if not required)\n",
    "        mean_probs = np.mean(probs, axis=0)\n",
    "        #print(mean_probs)\n",
    "        \n",
    "        # Determine the predicted class for this num and increment the counter\n",
    "        predicted_class_idx = np.argmax(mean_probs)\n",
    "        predicted_class = classnames[predicted_class_idx]\n",
    "        results_dict[predicted_class][\"predictions\"] += 1\n",
    "\n",
    "    return results_dict\n",
    "\n",
    "\n",
    "classnames = [\"birds\", \"chainsaw\", \"fire\", \"handsaw\", \"helicopter\"]\n",
    "classname = \"birds\"\n",
    "\n",
    "melvecs = []\n",
    "for num in num_range:\n",
    "    melvec = np.loadtxt(f\"melvecs_txt_h5a3/birds/melvec_{num}.txt\", \n",
    "                    dtype=str, \n",
    "                    converters={0: lambda x: int(x, 16)})\n",
    "    melvec = np.array(melvec, dtype=np.uint16)\n",
    "    melvecs.append(melvec)\n",
    "\n",
    "results_dict_1 = get_results_dic(melvecs, 1, classname)\n",
    "results_dict_2 = get_results_dic(melvecs, 2, classname)\n",
    "results_dict_3 = get_results_dic(melvecs, 3, classname)\n",
    "results_dict_4 = get_results_dic(melvecs, 4, classname)\n",
    "results_dict_5 = get_results_dic(melvecs, 5, classname)\n",
    "\n",
    "\"\"\"\n",
    "results_dict_1 = get_results_dic_OLD(dataset, 1, classname)\n",
    "results_dict_2 = get_results_dic_OLD(dataset, 2, classname)\n",
    "results_dict_3 = get_results_dic_OLD(dataset, 3, classname)\n",
    "results_dict_4 = get_results_dic_OLD(dataset, 4, classname)\n",
    "results_dict_5 = get_results_dic_OLD(dataset, 5, classname)\n",
    "\"\"\"\n",
    "\n",
    "#Display results\n",
    "print(\"\\nResults Dictionary 0:\")\n",
    "for c, data in results_dict_1.items():\n",
    "    print(f\"{c}:\")\n",
    "    print(f\"  Total Predictions: {data['predictions']}\")\n",
    "\n",
    "# Display results\n",
    "print(\"\\nResults Dictionary 5:\")\n",
    "for c, data in results_dict_5.items():\n",
    "    print(f\"{c}:\")\n",
    "    print(f\"  Total Predictions: {data['predictions']}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_bar_chart(classnames, classname, *results_dicts):\n",
    "    print(classname)\n",
    "    \"\"\"\n",
    "    Plots a bar chart comparing the total prediction counts for each classname across multiple dictionaries.\n",
    "    \n",
    "    Parameters:\n",
    "    - classnames (list): List of labels for the x-axis.\n",
    "    - *results_dicts (dict): Variable number of dictionaries containing the results to plot.\n",
    "    \"\"\"\n",
    "    # Ensure at most 6 dictionaries are passed\n",
    "    if len(results_dicts) > 6:\n",
    "        raise ValueError(\"The function can accept a maximum of 6 dictionaries.\")\n",
    "\n",
    "    # Create a bar width and position offsets for up to 6 dictionaries\n",
    "    bar_width = 0.15\n",
    "    n_win = len(results_dicts)  # Number of \"windows\" corresponds to the number of dictionaries\n",
    "    \n",
    "    # Prepare figure\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "\n",
    "    # Loop through each dictionary and plot the total prediction counts\n",
    "    for idx, results_dict in enumerate(results_dicts):\n",
    "        # Extract total counts for each classname\n",
    "        total_counts = [results_dict[classname][\"predictions\"] for classname in classnames]\n",
    "        percentage = (np.array(total_counts) / num_range.stop)*100\n",
    "        #print(percentage)\n",
    "        #print(classname)\n",
    "        #Create a mapping such that the index number gives the class name\n",
    "        percentage_dict = {classnames[i]: percentage[i] for i in range(len(classnames))}\n",
    "        #print(percentage_dict)\n",
    "\n",
    "        \n",
    "        # Plot the bars with some spacing based on the window index (idx)\n",
    "        plt.bar(\n",
    "            np.arange(len(classnames)) * 2 * n_win + idx,  \n",
    "            percentage,# Space bars by n_win,\n",
    "            alpha=0.9, \n",
    "            label= f\"No memory: {percentage_dict.get(classname, 0):.0f}%\" if (idx+1) == 1 else f\"{idx+1} Windows: {percentage_dict.get(classname, 0):.0f}%\",\n",
    "        )\n",
    "    \n",
    "    # Adjust x-axis ticks\n",
    "    plt.gca().set_xticks(np.arange(len(classnames)) * 2 * n_win + 2)\n",
    "    plt.gca().set_xticklabels(classnames)\n",
    "    \n",
    "    # Add labels, legend, and title\n",
    "    plt.xlabel(\"Classnames\")\n",
    "    plt.ylabel(\"Prediction percentage (%)\")\n",
    "    plt.title(f\"Memory usage results, for {classname}\")\n",
    "    plt.legend()\n",
    "    \n",
    "    # Display the plot\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"figures/memory_effect_{classname}.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "classnames = [\"birds\", \"chainsaw\", \"fire\", \"handsaw\", \"helicopter\"]\n",
    "# Assuming results_dict_0 to results_dict_5 are already created\n",
    "plot_bar_chart(classnames , classname,results_dict_1, results_dict_2, results_dict_3, results_dict_4, results_dict_5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question:\n",
    "Are the bar plots similar between the 5 windows of the same 5s-long sound? With the default sound, how often does the right class win?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO COMPLETE\n",
    "# Answer the question above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answers\n",
    "The bar plots are sometimes similar between the 5 windows, leading to a correct classification. However, it not not alwars the case (it would have been ideal) depending to the num index. However, if our model was better, the bar plots would be simillar. \\\n",
    "\n",
    "Birds: win ; chainsaw: win; fire: lost to helicopter ; handsaw: lost to chainsaw; helicopter: win \\\n",
    "3 wins/5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If it is relevant to combine $N$ consecutive feature vectors, there are many ways to output a prediction from it:\n",
    "- **Naive**: select the class that has the highest probability among all the considered feature vectors.\n",
    "- **Majority voting**: simply select the class that appears most often as the maximum probability of a feature vector.\n",
    "- **Average the feature representation**: compute the average of all feature vectors and classify from this average.\n",
    "- **Maximum Likelihood**: take a probabilistic approach and consider selecting class $i$ as\n",
    "    $$\n",
    "        \\text{argmax}_i~ \\log \\bigg(\\prod_{n=0}^{N-1} P(y[n]=i) \\bigg)\n",
    "        = \\text{argmax}_i~ \\sum_{n=0}^{N-1} \\log P(y[n]=i)\n",
    "    $$\n",
    "    with $y[n]$ the model prediction for the feature vector $n$.\n",
    "\n",
    "It will be part of your work to decide how you want to exploit the time information in your predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you have all the necessary material to test a new classification model and make some objective analysis of its performances. <br>\n",
    "Follow the instructions on Moodle [written here](https://moodle.uclouvain.be/mod/assign/view.php?id=204607) to see what is expected in your ``fifth report (R5)``. <br>\n",
    "A lot of other classification models are already implemented by SKlearn, check the [SKlearn API](https://scikit-learn.org/stable/supervised_learning.html#supervised-learning). Don't hesitate to read some opinions and discussions on the forums or even articles to help you in the model choice. The most motivated of you are even allowed to give a try to more than one additional model, it is time smartly invested for the upcoming weeks of this project! Although we expect only one characterization in the ``R5``.\n",
    "\n",
    "Also, don't hesitate to get information from the Internet to learn how people use to deal with sound classification. We mention for example this idea of transfer learning that could be interesting for you in the second semester: https://www.youtube.com/watch?v=uCGROOUO_wY&t=1s "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LELEC210X",
   "language": "python",
   "name": "lelec210x"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "46df200377d403be22c796785365123e6a374b5da08e8292e6b2afda659c5a28"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
